{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8699c11d-686c-4415-b006-cedfd857f607",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c614db39-9cf8-460f-9e79-922694ba5b26",
   "metadata": {},
   "source": [
    "Ans: Simple linear regression is a technique used when there is a single independent variable that is believed to have a linear relationship with the dependent variable. It aims to find the best-fit line that minimizes the sum of the squared differences between the observed data points and the predicted values on the line. \n",
    "\n",
    "Example: Lets take raining and the yielding dataset.By applying simple linear regression ,we can estimate the regression line that best fits the data and predict the yielding based on the easures of raining.\n",
    "\n",
    "Multiple linear regression extends simple linear regression by considering multiple independent variables that may influence the dependent variable. It allows for modeling more complex relationships between the dependent variable and two or more independent variables. \n",
    "\n",
    "Example:Suppose we want to predict the price of a house (Y) based on various factors such as the size of the house (X₁), the number of bedrooms (X₂), and the location (X₃). We gather data on multiple houses, including the sizes, number of bedrooms, locations, and their corresponding prices. By utilizing multiple linear regression, we can create a model that considers all these variables and predicts the price of a house based on these factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d5e42-f61f-4577-bb63-97bc7ffbaf62",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d33f07-7b79-4b9b-9cf5-9e1b8ff091cc",
   "metadata": {},
   "source": [
    "Ans: The assumptions are 1.linearity, 2.independence, 3.homoscedasticity, 4. Normality, 5.No multicolinearity.\n",
    "\n",
    "To check the assumption, we can do some visual inseption by plotting scatter plot or histogram.\n",
    "We can do some statistical tests like,Shapiro-Wilk test or the Kolmogorov-Smirnov test. Then we can do residual analysis to check the outliers and lastly we can croo validate the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf68d1-43b8-40a8-bf51-95e0c7a8e617",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe49765-fec4-4281-90ca-5eaacb34fd72",
   "metadata": {},
   "source": [
    "Ans: In a linear regression model, the slope and intercept represent the estimated relationship between the independent variable(s) and the dependent variable.\n",
    "1. Intercept is the value of the dependent variable when all independent variables are zero. It represents the baseline or starting point of the relationship between the variables, regardless of the values of the independent variable(s). It indicates the expected value of the dependent variable when there is no influence from the independent variable(s).\n",
    "\n",
    "2. Slope  represents the change in the dependent variable for a one-unit change in the independent variable, holding other variables constant. It reflects the rate or magnitude of the effect that the independent variable has on the dependent variable. \n",
    "\n",
    "Example:If we take the example of rainign and yield, then if rhe slope is 0.5, then if the rain increases 1 unit, then the Yield will be increases by 0.5 units. i.e.if the rain increases by 25 cm the  the model predicts an increase in the  yielding by 25*.5=12.5 unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754280c5-5782-43db-b076-eaa5285708b4",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032939c-31b7-47e8-a1bc-064b52dc9fc0",
   "metadata": {},
   "source": [
    "Ans: Gradient descent is an optimization algorithm commonly used in machine learning for finding the optimal values of the parameters of a model. It is used to minimize the cost or loss function associated with the model by iteratively adjusting the parameter values in the direction of steepest descent.\n",
    "\n",
    "Gradient descent is used in various machine learning algorithms, including linear regression, logistic regression, neural networks, and many others. It is an essential component of training these models as it enables them to find the optimal set of parameters that minimize the difference between the predicted outputs and the actual outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a7b7f-e0d4-4d28-a5d7-fb1dc2f6505c",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457c9ce-0463-40b8-8bf6-652036698512",
   "metadata": {},
   "source": [
    "Ans: Multiple linear regression extends simple linear regression by considering multiple independent variables that may influence the dependent variable. It allows for modeling more complex relationships between the dependent variable and two or more independent variables. \n",
    "Example:Suppose we want to predict the price of a house (Y) based on various factors such as the size of the house (X₁), the number of bedrooms (X₂), and the location (X₃). We gather data on multiple houses, including the sizes, number of bedrooms, locations, and their corresponding prices. By utilizing multiple linear regression, we can create a model that considers all these variables and predicts the price of a house based on these factors.\n",
    "\n",
    "Simple linear regression involves one independent variable and assumes a linear relationship, while multiple linear regression involves two or more independent variables and allows for more complex relationships. Multiple linear regression provides a more comprehensive and flexible approach to modeling the relationship between the dependent variable and multiple predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc9873-43f5-489b-9f0d-1a2d623963fd",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59fbdd-8698-4e18-9ace-4d8a6d028c5d",
   "metadata": {},
   "source": [
    "Ans: Multicollinearity refers to a situation in multiple linear regression where two or more independent variables are highly correlated with each other. It can cause problems in the regression analysis, making it challenging to interpret the coefficients accurately and affecting the stability and reliability of the model.\n",
    "\n",
    "To detect and address multicollinearity, the following methods can be employed:\n",
    "1. Correlation Analysis\n",
    "2. Variance Inflation Factor\n",
    "3. EIgen Value Analysis\n",
    "4. Eigenvector Analysis\n",
    "5. Adrresing Multicolinearityby featre selecytion, Ridge or Lasso regression and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec1cc8-9e8a-4a75-8f7b-827b7d32c519",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a981472-a03d-4d10-8959-ea3d5de8a405",
   "metadata": {},
   "source": [
    "Ans: Polynomial regression is a form of regression analysis that allows for a nonlinear relationship between the independent variable(s) and the dependent variable. It extends the concept of linear regression by including higher-order polynomial terms as predictors in the model.\n",
    "\n",
    "In polynomial regression there presents non linear relationship with higher order polynomial terms  but in  linear regression , there is   a linear relationships between variables . It provides flexibility in modeling complex patterns but requires careful consideration of overfitting, interpretability, and extrapolation. In linear regresion the best fit line will be a straight line but in polynomial regression the best fit line will be a polynomial curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396b6dc-0b19-47a2-aa33-2a81a11818f1",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a236fd-6ed5-46d6-8f6c-b80643922fcb",
   "metadata": {},
   "source": [
    " Ans: Advantages of Polynomial Regression over Linear Regression:\n",
    "\n",
    "1. Capturing Nonlinear Relationships: Polynomial regression can model and capture nonlinear relationships between the independent and dependent variables. It can fit curved or nonlinear patterns in the data, whereas linear regression assumes a linear relationship.\n",
    "\n",
    "2. Flexibility: By including higher-order polynomial terms, polynomial regression provides more flexibility in fitting the data. It can accommodate more complex relationships and capture nuances that may be missed by linear regression.\n",
    "\n",
    "Disadvantages of Polynomial Regression compared to Linear Regression:\n",
    "\n",
    "1. Overfitting: Polynomial regression models with high-degree polynomials can be prone to overfitting. Overfitting occurs when the model fits the noise or random fluctuations in the data rather than the underlying true pattern. This can lead to poor performance on unseen data.\n",
    "\n",
    "2. Interpretability: As the degree of the polynomial increases, the interpretation of the coefficients becomes more challenging. It becomes harder to attribute meaningful explanations to the effects of individual variables. This lack of interpretability can limit the insights gained from the model.\n",
    "\n",
    "3. Extrapolation: Polynomial regression models may not accurately predict values outside the range of the observed data. Extrapolating beyond the range of the data can lead to unreliable predictions.\n",
    "\n",
    " When we see the non linear relation between the variables, then we prefer the Polynomial regression  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db966c-84d3-4114-a21c-f120e1efe282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb4626-b7d5-4443-8f93-5994060f2264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74897b8d-47a4-44b1-b5a3-734db124b833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7c9fd-adfe-4add-ab7f-f37546c478ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
